# NDH è‡ªå‹•åŒ–åˆå§‹è¨­å®šèˆ‡é€£æ¥å™¨é…ç½®ç³»çµ±

**æ–‡ä»¶ç‰ˆæœ¬**: 1.0  
**æœ€å¾Œæ›´æ–°**: 2025-10-15  
**ä½œè€…**: æ—å¿—éŒš Michael Lin(Chih Cheng Lin)(Chih Cheng Lin) Michael Lin (Chih Cheng Lin)

---

## ç›®éŒ„

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [è¨­è¨ˆç†å¿µ](#è¨­è¨ˆç†å¿µ)
3. [è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶](#è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶)
4. [é€£æ¥å™¨é¡å‹](#é€£æ¥å™¨é¡å‹)
5. [åˆå§‹è¨­å®šæµç¨‹](#åˆå§‹è¨­å®šæµç¨‹)
6. [Web UI è¨­å®šä»‹é¢](#web-ui-è¨­å®šä»‹é¢)
7. [CLI è¨­å®šå·¥å…·](#cli-è¨­å®šå·¥å…·)
8. [é…ç½®æª”æ¡ˆæ ¼å¼](#é…ç½®æª”æ¡ˆæ ¼å¼)
9. [é€£æ¥å™¨æ¸¬è©¦èˆ‡é©—è­‰](#é€£æ¥å™¨æ¸¬è©¦èˆ‡é©—è­‰)
10. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
11. [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)

---

## æ¦‚è¿°

NDH è‡ªå‹•åŒ–åˆå§‹è¨­å®šèˆ‡é€£æ¥å™¨é…ç½®ç³»çµ±æä¾›äº†ä¸€å€‹æ™ºèƒ½åŒ–çš„éƒ¨ç½²é«”é©—ï¼Œèƒ½å¤ è‡ªå‹•ç™¼ç¾ç¶²è·¯ä¸Šçš„å„ç¨®å·¥æ¥­ç³»çµ±ï¼ˆæ™‚åºè³‡æ–™åº«ã€Omniverseã€MESã€ERP ç­‰ï¼‰ï¼Œä¸¦è‡ªå‹•é…ç½®é€£æ¥å™¨ã€‚

### æ ¸å¿ƒç›®æ¨™

1. **é™ä½éƒ¨ç½²é–€æª»**: å¾æ•¸å¤©åˆ°æ•¸å°æ™‚
2. **æ¸›å°‘é…ç½®éŒ¯èª¤**: è‡ªå‹•é©—è­‰å’Œæ¸¬è©¦
3. **æå‡ä½¿ç”¨è€…é«”é©—**: è¦–è¦ºåŒ–çš„è¨­å®šä»‹é¢
4. **æ”¯æ´å¤šç¨®éƒ¨ç½²å ´æ™¯**: å–®æ©Ÿã€å¢é›†ã€é›²ç«¯

### æ ¸å¿ƒåŠŸèƒ½

- âœ… **è‡ªå‹•ç™¼ç¾**: æƒæç¶²è·¯ï¼Œç™¼ç¾å¯ç”¨çš„ç³»çµ±
- âœ… **æ™ºèƒ½é…ç½®**: æ ¹æ“šç³»çµ±é¡å‹è‡ªå‹•ç”Ÿæˆé…ç½®
- âœ… **é€£æ¥æ¸¬è©¦**: è‡ªå‹•æ¸¬è©¦é€£æ¥ä¸¦é©—è­‰åŠŸèƒ½
- âœ… **é…ç½®ç®¡ç†**: åŒ¯å…¥/åŒ¯å‡ºé…ç½®ï¼Œç‰ˆæœ¬æ§åˆ¶
- âœ… **æ•…éšœè¨ºæ–·**: è‡ªå‹•è¨ºæ–·é€£æ¥å•é¡Œä¸¦æä¾›è§£æ±ºæ–¹æ¡ˆ

---

## è¨­è¨ˆç†å¿µ

### 1. é›¶é…ç½®å„ªå…ˆ (Zero-Configuration First)

ç³»çµ±æ‡‰è©²èƒ½å¤ åœ¨æ²’æœ‰ä»»ä½•æ‰‹å‹•é…ç½®çš„æƒ…æ³ä¸‹è‡ªå‹•ç™¼ç¾å’Œé€£æ¥åˆ°å¸¸è¦‹çš„ç³»çµ±ã€‚

**ç¯„ä¾‹**:
```bash
# å•Ÿå‹• NDHï¼Œè‡ªå‹•ç™¼ç¾ä¸¦é€£æ¥æ‰€æœ‰ç³»çµ±
$ ndh-admin init --auto-discover

ğŸ” æ­£åœ¨æƒæç¶²è·¯...
âœ… ç™¼ç¾ InfluxDB: 192.168.1.100:8086
âœ… ç™¼ç¾ Omniverse Nucleus: 192.168.1.101:3009
âœ… ç™¼ç¾ MES (SAP ME): 192.168.1.102:8080
âœ… ç™¼ç¾ ERP (SAP S/4HANA): 192.168.1.103:443

ğŸ”§ æ­£åœ¨è‡ªå‹•é…ç½®é€£æ¥å™¨...
âœ… InfluxDB é€£æ¥å™¨å·²é…ç½®
âœ… Omniverse é€£æ¥å™¨å·²é…ç½®
âœ… MES é€£æ¥å™¨å·²é…ç½®
âœ… ERP é€£æ¥å™¨å·²é…ç½®

âœ… NDH åˆå§‹åŒ–å®Œæˆï¼
```

### 2. æ¼¸é€²å¼é…ç½® (Progressive Configuration)

æ”¯æ´å¾ç°¡å–®åˆ°è¤‡é›œçš„æ¼¸é€²å¼é…ç½®ï¼š

1. **Level 1**: è‡ªå‹•ç™¼ç¾ + é è¨­é…ç½®
2. **Level 2**: æ‰‹å‹•èª¿æ•´éƒ¨åˆ†åƒæ•¸
3. **Level 3**: å®Œå…¨è‡ªè¨‚é…ç½®

### 3. é…ç½®å³ä»£ç¢¼ (Configuration as Code)

æ‰€æœ‰é…ç½®éƒ½å¯ä»¥åŒ¯å‡ºç‚º YAML/JSON æª”æ¡ˆï¼Œæ”¯æ´ç‰ˆæœ¬æ§åˆ¶å’Œè‡ªå‹•åŒ–éƒ¨ç½²ã€‚

### 4. å¯è§€æ¸¬æ€§ (Observability)

é…ç½®éç¨‹çš„æ¯ä¸€æ­¥éƒ½æœ‰è©³ç´°çš„æ—¥èªŒå’Œç‹€æ…‹åé¥‹ã€‚

---

## è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶

### 1. ç¶²è·¯æƒæç­–ç•¥

#### 1.1 ä¸»å‹•æƒæ (Active Scanning)

**æ–¹æ³•**: æƒææŒ‡å®šçš„ IP ç¯„åœå’Œç«¯å£

```yaml
scan_config:
  ip_ranges:
    - "192.168.1.0/24"
    - "10.0.0.0/16"
  
  port_ranges:
    # æ™‚åºè³‡æ–™åº«
    - name: "InfluxDB"
      ports: [8086]
    - name: "TimescaleDB"
      ports: [5432]
    
    # Omniverse
    - name: "Omniverse Nucleus"
      ports: [3009, 3019, 3100]
    
    # MES
    - name: "SAP ME"
      ports: [8080, 50000]
    - name: "Siemens Opcenter"
      ports: [80, 443]
    
    # ERP
    - name: "SAP S/4HANA"
      ports: [443, 3200, 3300]
    - name: "Oracle ERP Cloud"
      ports: [443]
  
  timeout_seconds: 5
  max_concurrent_scans: 100
```

**å¯¦ä½œ**:

```python
import socket
import concurrent.futures
from typing import List, Tuple

class NetworkScanner:
    def __init__(self, config: dict):
        self.config = config
    
    def scan_port(self, ip: str, port: int, timeout: int = 5) -> bool:
        """æƒæå–®å€‹ç«¯å£"""
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(timeout)
                result = sock.connect_ex((ip, port))
                return result == 0
        except:
            return False
    
    def scan_ip_range(self, ip_range: str, ports: List[int]) -> List[Tuple[str, int]]:
        """æƒæ IP ç¯„åœ"""
        import ipaddress
        
        network = ipaddress.ip_network(ip_range)
        discovered = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:
            futures = []
            for ip in network.hosts():
                for port in ports:
                    future = executor.submit(self.scan_port, str(ip), port)
                    futures.append((future, str(ip), port))
            
            for future, ip, port in futures:
                if future.result():
                    discovered.append((ip, port))
        
        return discovered
    
    def discover_systems(self) -> dict:
        """ç™¼ç¾æ‰€æœ‰ç³»çµ±"""
        discovered_systems = {}
        
        for port_config in self.config['port_ranges']:
            system_name = port_config['name']
            ports = port_config['ports']
            
            print(f"ğŸ” æ­£åœ¨æƒæ {system_name}...")
            
            for ip_range in self.config['ip_ranges']:
                found = self.scan_ip_range(ip_range, ports)
                
                if found:
                    if system_name not in discovered_systems:
                        discovered_systems[system_name] = []
                    discovered_systems[system_name].extend(found)
        
        return discovered_systems
```

#### 1.2 è¢«å‹•ç™¼ç¾ (Passive Discovery)

**æ–¹æ³•**: ç›£è½ç¶²è·¯æµé‡ï¼Œè­˜åˆ¥ç³»çµ±

- mDNS/Bonjour æœå‹™ç™¼ç¾
- SSDP (Simple Service Discovery Protocol)
- ç›£è½ç‰¹å®šçš„å»£æ’­/å¤šæ’­è¨Šæ¯

**å¯¦ä½œ**:

```python
from zeroconf import ServiceBrowser, Zeroconf

class PassiveDiscovery:
    def __init__(self):
        self.zeroconf = Zeroconf()
        self.discovered_services = []
    
    def on_service_state_change(self, zeroconf, service_type, name, state_change):
        """æœå‹™ç‹€æ…‹è®Šæ›´å›èª¿"""
        if state_change is ServiceStateChange.Added:
            info = zeroconf.get_service_info(service_type, name)
            if info:
                self.discovered_services.append({
                    'name': name,
                    'type': service_type,
                    'address': socket.inet_ntoa(info.addresses[0]),
                    'port': info.port,
                    'properties': info.properties
                })
    
    def discover(self, service_types: List[str], timeout: int = 10):
        """ç™¼ç¾æœå‹™"""
        browsers = []
        for service_type in service_types:
            browser = ServiceBrowser(self.zeroconf, service_type, 
                                   handlers=[self.on_service_state_change])
            browsers.append(browser)
        
        time.sleep(timeout)
        
        self.zeroconf.close()
        return self.discovered_services
```

#### 1.3 é…ç½®æª”æ¡ˆç™¼ç¾ (Configuration File Discovery)

**æ–¹æ³•**: è®€å–é å…ˆé…ç½®çš„ç³»çµ±æ¸…å–®

```yaml
# /etc/ndh/systems.yaml
systems:
  - name: "Production InfluxDB"
    type: "influxdb"
    host: "influxdb.production.local"
    port: 8086
  
  - name: "Omniverse Nucleus"
    type: "omniverse"
    host: "omniverse.production.local"
    port: 3009
  
  - name: "SAP ME"
    type: "mes"
    vendor: "sap"
    host: "mes.production.local"
    port: 8080
```

---

### 2. ç³»çµ±è­˜åˆ¥èˆ‡æŒ‡ç´‹è­˜åˆ¥

ç™¼ç¾ç«¯å£å¾Œï¼Œéœ€è¦è­˜åˆ¥ç³»çµ±é¡å‹å’Œç‰ˆæœ¬ã€‚

#### 2.1 HTTP Banner è­˜åˆ¥

```python
import requests

def identify_http_service(host: str, port: int) -> dict:
    """é€é HTTP è­˜åˆ¥æœå‹™"""
    try:
        response = requests.get(f"http://{host}:{port}", timeout=5)
        
        # æª¢æŸ¥ Server header
        server = response.headers.get('Server', '')
        
        # InfluxDB
        if 'InfluxDB' in server:
            return {
                'type': 'influxdb',
                'version': extract_version(server)
            }
        
        # æª¢æŸ¥ç‰¹å®šçš„ API ç«¯é»
        # Omniverse Nucleus
        if port == 3009:
            try:
                nucleus_response = requests.get(
                    f"http://{host}:{port}/api/version", 
                    timeout=5
                )
                if nucleus_response.status_code == 200:
                    return {
                        'type': 'omniverse_nucleus',
                        'version': nucleus_response.json().get('version')
                    }
            except:
                pass
        
        return {'type': 'unknown'}
    
    except:
        return {'type': 'unknown'}
```

#### 2.2 è³‡æ–™åº«æŒ‡ç´‹è­˜åˆ¥

```python
def identify_database(host: str, port: int) -> dict:
    """è­˜åˆ¥è³‡æ–™åº«é¡å‹"""
    
    # PostgreSQL/TimescaleDB (port 5432)
    if port == 5432:
        try:
            import psycopg2
            conn = psycopg2.connect(
                host=host,
                port=port,
                user='postgres',
                password='',
                connect_timeout=5
            )
            cursor = conn.cursor()
            cursor.execute("SELECT version()")
            version = cursor.fetchone()[0]
            
            # æª¢æŸ¥æ˜¯å¦ç‚º TimescaleDB
            cursor.execute(
                "SELECT * FROM pg_extension WHERE extname = 'timescaledb'"
            )
            is_timescaledb = cursor.fetchone() is not None
            
            conn.close()
            
            return {
                'type': 'timescaledb' if is_timescaledb else 'postgresql',
                'version': version
            }
        except:
            return {'type': 'postgresql', 'version': 'unknown'}
    
    return {'type': 'unknown'}
```

#### 2.3 MES/ERP ç³»çµ±è­˜åˆ¥

```python
def identify_mes_erp(host: str, port: int) -> dict:
    """è­˜åˆ¥ MES/ERP ç³»çµ±"""
    
    # SAP ç³»çµ±é€šå¸¸æœ‰ç‰¹å®šçš„ HTTP ç«¯é»
    try:
        # SAP ME
        response = requests.get(
            f"http://{host}:{port}/sap/public/info",
            timeout=5
        )
        if response.status_code == 200:
            return {
                'type': 'mes',
                'vendor': 'sap',
                'product': 'SAP ME'
            }
    except:
        pass
    
    # Siemens Opcenter
    try:
        response = requests.get(
            f"http://{host}:{port}/Opcenter/api/info",
            timeout=5
        )
        if response.status_code == 200:
            return {
                'type': 'mes',
                'vendor': 'siemens',
                'product': 'Opcenter'
            }
    except:
        pass
    
    return {'type': 'unknown'}
```

---

## é€£æ¥å™¨é¡å‹

### 1. æ™‚åºè³‡æ–™åº«é€£æ¥å™¨

#### 1.1 InfluxDB é€£æ¥å™¨

**è‡ªå‹•é…ç½®**:

```python
class InfluxDBConnectorAutoConfig:
    def discover_and_configure(self, host: str, port: int) -> dict:
        """è‡ªå‹•ç™¼ç¾ä¸¦é…ç½® InfluxDB"""
        
        # 1. æª¢æ¸¬ç‰ˆæœ¬
        version = self.detect_version(host, port)
        
        # 2. æ¸¬è©¦é€£æ¥
        if not self.test_connection(host, port):
            raise Exception("ç„¡æ³•é€£æ¥åˆ° InfluxDB")
        
        # 3. åˆ—å‡ºå¯ç”¨çš„è³‡æ–™åº«/bucket
        databases = self.list_databases(host, port)
        
        # 4. ç”Ÿæˆé…ç½®
        config = {
            'type': 'influxdb',
            'version': version,
            'host': host,
            'port': port,
            'protocol': 'http',
            'databases': databases,
            'default_database': databases[0] if databases else 'ndh',
            'retention_policy': 'autogen',
            'timeout': 10,
            'max_retries': 3
        }
        
        return config
    
    def detect_version(self, host: str, port: int) -> str:
        """æª¢æ¸¬ InfluxDB ç‰ˆæœ¬"""
        import requests
        
        response = requests.get(f"http://{host}:{port}/ping")
        version_header = response.headers.get('X-Influxdb-Version', 'unknown')
        
        if version_header.startswith('1.'):
            return '1.x'
        elif version_header.startswith('2.'):
            return '2.x'
        else:
            return 'unknown'
    
    def list_databases(self, host: str, port: int) -> List[str]:
        """åˆ—å‡ºè³‡æ–™åº«"""
        from influxdb import InfluxDBClient
        
        client = InfluxDBClient(host=host, port=port)
        databases = client.get_list_database()
        
        return [db['name'] for db in databases]
```

**é…ç½®ç¯„ä¾‹**:

```yaml
connectors:
  - name: "influxdb_production"
    type: "influxdb"
    version: "2.x"
    connection:
      host: "192.168.1.100"
      port: 8086
      protocol: "http"
      org: "idtf"
      bucket: "factory_data"
      token: "${INFLUXDB_TOKEN}"  # å¾ç’°å¢ƒè®Šæ•¸è®€å–
    
    settings:
      timeout: 10
      max_retries: 3
      batch_size: 5000
      flush_interval: 1000  # ms
    
    health_check:
      enabled: true
      interval: 30  # seconds
      endpoint: "/health"
```

#### 1.2 TimescaleDB é€£æ¥å™¨

**è‡ªå‹•é…ç½®**:

```python
class TimescaleDBConnectorAutoConfig:
    def discover_and_configure(self, host: str, port: int) -> dict:
        """è‡ªå‹•ç™¼ç¾ä¸¦é…ç½® TimescaleDB"""
        
        import psycopg2
        
        # 1. æ¸¬è©¦é€£æ¥
        conn = psycopg2.connect(
            host=host,
            port=port,
            user='postgres',
            password='',
            dbname='postgres'
        )
        
        cursor = conn.cursor()
        
        # 2. æª¢æ¸¬ TimescaleDB ç‰ˆæœ¬
        cursor.execute(
            "SELECT extversion FROM pg_extension WHERE extname = 'timescaledb'"
        )
        timescaledb_version = cursor.fetchone()[0]
        
        # 3. åˆ—å‡ºè³‡æ–™åº«
        cursor.execute("SELECT datname FROM pg_database WHERE datistemplate = false")
        databases = [row[0] for row in cursor.fetchall()]
        
        # 4. åˆ—å‡º hypertables
        cursor.execute("""
            SELECT hypertable_schema, hypertable_name
            FROM timescaledb_information.hypertables
        """)
        hypertables = cursor.fetchall()
        
        conn.close()
        
        # 5. ç”Ÿæˆé…ç½®
        config = {
            'type': 'timescaledb',
            'version': timescaledb_version,
            'host': host,
            'port': port,
            'databases': databases,
            'default_database': 'ndh',
            'hypertables': [
                {'schema': schema, 'table': table}
                for schema, table in hypertables
            ],
            'connection_pool': {
                'min_size': 5,
                'max_size': 20
            }
        }
        
        return config
```

---

### 2. Omniverse é€£æ¥å™¨

#### 2.1 è‡ªå‹•ç™¼ç¾ Omniverse Nucleus

**å¯¦ä½œ**:

```python
class OmniverseConnectorAutoConfig:
    def discover_and_configure(self, host: str, port: int = 3009) -> dict:
        """è‡ªå‹•ç™¼ç¾ä¸¦é…ç½® Omniverse Nucleus"""
        
        import requests
        
        # 1. æª¢æ¸¬ Nucleus ç‰ˆæœ¬
        response = requests.get(f"http://{host}:{port}/api/version")
        version_info = response.json()
        
        # 2. åˆ—å‡ºå¯ç”¨çš„ USD å€‰åº«
        response = requests.get(f"http://{host}:{port}/api/repos")
        repos = response.json()
        
        # 3. æ¸¬è©¦ USD è¨ªå•
        test_repo = repos[0] if repos else None
        if test_repo:
            usd_url = f"omniverse://{host}/{test_repo['name']}"
            if not self.test_usd_access(usd_url):
                raise Exception("ç„¡æ³•è¨ªå• USD å€‰åº«")
        
        # 4. ç”Ÿæˆé…ç½®
        config = {
            'type': 'omniverse',
            'nucleus_version': version_info.get('version'),
            'host': host,
            'port': port,
            'repos': repos,
            'default_repo': test_repo['name'] if test_repo else 'Projects',
            'usd_stage_path': f"omniverse://{host}/{test_repo['name']}/Factory/factory.usd",
            'connector_settings': {
                'sync_interval': 1000,  # ms
                'batch_updates': True,
                'enable_live_sync': True
            }
        }
        
        return config
    
    def test_usd_access(self, usd_url: str) -> bool:
        """æ¸¬è©¦ USD è¨ªå•"""
        try:
            from pxr import Usd
            stage = Usd.Stage.Open(usd_url)
            return stage is not None
        except:
            return False
```

**é…ç½®ç¯„ä¾‹**:

```yaml
connectors:
  - name: "omniverse_production"
    type: "omniverse"
    nucleus_version: "2023.2.0"
    connection:
      host: "192.168.1.101"
      port: 3009
      repo: "Projects"
      usd_stage_path: "omniverse://192.168.1.101/Projects/Factory/factory.usd"
      auth:
        username: "${OMNIVERSE_USER}"
        password: "${OMNIVERSE_PASSWORD}"
    
    settings:
      sync_interval: 1000  # ms
      batch_updates: true
      enable_live_sync: true
      max_prims_per_batch: 1000
    
    health_check:
      enabled: true
      interval: 60  # seconds
```

---

### 3. MES é€£æ¥å™¨

#### 3.1 SAP ME é€£æ¥å™¨

**è‡ªå‹•ç™¼ç¾**:

```python
class SAPMEConnectorAutoConfig:
    def discover_and_configure(self, host: str, port: int = 8080) -> dict:
        """è‡ªå‹•ç™¼ç¾ä¸¦é…ç½® SAP ME"""
        
        import requests
        
        # 1. æª¢æ¸¬ SAP ME ç‰ˆæœ¬
        response = requests.get(
            f"http://{host}:{port}/sap/public/info",
            timeout=10
        )
        info = response.json()
        
        # 2. æ¸¬è©¦ OData API
        odata_url = f"http://{host}:{port}/odata/v4"
        response = requests.get(f"{odata_url}/$metadata", timeout=10)
        
        if response.status_code != 200:
            raise Exception("ç„¡æ³•è¨ªå• SAP ME OData API")
        
        # 3. åˆ—å‡ºå¯ç”¨çš„å¯¦é«”é›†
        metadata = response.text
        entity_sets = self.parse_entity_sets(metadata)
        
        # 4. ç”Ÿæˆé…ç½®
        config = {
            'type': 'mes',
            'vendor': 'sap',
            'product': 'SAP ME',
            'version': info.get('version'),
            'host': host,
            'port': port,
            'api_type': 'odata_v4',
            'base_url': odata_url,
            'entity_sets': entity_sets,
            'polling_interval': 5000,  # ms
            'supported_operations': [
                'get_work_orders',
                'get_operations',
                'report_production',
                'get_material_status'
            ]
        }
        
        return config
    
    def parse_entity_sets(self, metadata: str) -> List[str]:
        """è§£æ OData metadata ä¸­çš„å¯¦é«”é›†"""
        import xml.etree.ElementTree as ET
        
        root = ET.fromstring(metadata)
        entity_sets = []
        
        for entity_set in root.findall('.//{*}EntitySet'):
            entity_sets.append(entity_set.get('Name'))
        
        return entity_sets
```

**é…ç½®ç¯„ä¾‹**:

```yaml
connectors:
  - name: "sap_me_production"
    type: "mes"
    vendor: "sap"
    product: "SAP ME"
    version: "15.4"
    connection:
      host: "192.168.1.102"
      port: 8080
      protocol: "http"
      base_url: "http://192.168.1.102:8080/odata/v4"
      auth:
        type: "basic"
        username: "${SAP_ME_USER}"
        password: "${SAP_ME_PASSWORD}"
    
    settings:
      polling_interval: 5000  # ms
      batch_size: 100
      timeout: 30
    
    mappings:
      work_order: "WorkOrders"
      operation: "Operations"
      material: "Materials"
      production_data: "ProductionData"
    
    health_check:
      enabled: true
      interval: 30  # seconds
      endpoint: "/sap/public/ping"
```

#### 3.2 Siemens Opcenter é€£æ¥å™¨

**è‡ªå‹•ç™¼ç¾**:

```python
class OpcenterConnectorAutoConfig:
    def discover_and_configure(self, host: str, port: int = 443) -> dict:
        """è‡ªå‹•ç™¼ç¾ä¸¦é…ç½® Siemens Opcenter"""
        
        import requests
        
        # 1. æª¢æ¸¬ Opcenter ç‰ˆæœ¬
        response = requests.get(
            f"https://{host}:{port}/Opcenter/api/info",
            verify=False,
            timeout=10
        )
        info = response.json()
        
        # 2. æ¸¬è©¦ REST API
        api_url = f"https://{host}:{port}/Opcenter/api/v1"
        response = requests.get(
            f"{api_url}/workorders",
            verify=False,
            timeout=10
        )
        
        if response.status_code not in [200, 401]:  # 401 è¡¨ç¤ºéœ€è¦èªè­‰ï¼Œä½† API å¯ç”¨
            raise Exception("ç„¡æ³•è¨ªå• Opcenter REST API")
        
        # 3. ç”Ÿæˆé…ç½®
        config = {
            'type': 'mes',
            'vendor': 'siemens',
            'product': 'Opcenter',
            'version': info.get('version'),
            'host': host,
            'port': port,
            'api_type': 'rest',
            'base_url': api_url,
            'polling_interval': 5000,  # ms
            'supported_operations': [
                'get_work_orders',
                'get_operations',
                'report_production',
                'get_material_status',
                'get_equipment_status'
            ]
        }
        
        return config
```

---

### 4. ERP é€£æ¥å™¨

#### 4.1 SAP S/4HANA é€£æ¥å™¨

**è‡ªå‹•ç™¼ç¾**:

```python
class SAPS4HANAConnectorAutoConfig:
    def discover_and_configure(self, host: str, port: int = 443) -> dict:
        """è‡ªå‹•ç™¼ç¾ä¸¦é…ç½® SAP S/4HANA"""
        
        import requests
        
        # 1. æª¢æ¸¬ SAP ç³»çµ±
        response = requests.get(
            f"https://{host}:{port}/sap/public/info",
            verify=False,
            timeout=10
        )
        info = response.json()
        
        # 2. æ¸¬è©¦ OData API
        odata_url = f"https://{host}:{port}/sap/opu/odata/sap"
        response = requests.get(
            f"{odata_url}/API_PRODUCT_SRV/$metadata",
            verify=False,
            timeout=10
        )
        
        if response.status_code not in [200, 401]:
            raise Exception("ç„¡æ³•è¨ªå• SAP S/4HANA OData API")
        
        # 3. ç”Ÿæˆé…ç½®
        config = {
            'type': 'erp',
            'vendor': 'sap',
            'product': 'S/4HANA',
            'version': info.get('version'),
            'host': host,
            'port': port,
            'api_type': 'odata_v2',
            'base_url': odata_url,
            'polling_interval': 60000,  # ms (ERP é€šå¸¸ä¸éœ€è¦é »ç¹è¼ªè©¢)
            'supported_operations': [
                'get_materials',
                'get_purchase_orders',
                'get_sales_orders',
                'get_production_orders',
                'get_inventory'
            ]
        }
        
        return config
```

**é…ç½®ç¯„ä¾‹**:

```yaml
connectors:
  - name: "sap_s4hana_production"
    type: "erp"
    vendor: "sap"
    product: "S/4HANA"
    version: "2022"
    connection:
      host: "192.168.1.103"
      port: 443
      protocol: "https"
      base_url: "https://192.168.1.103/sap/opu/odata/sap"
      auth:
        type: "oauth2"
        client_id: "${SAP_CLIENT_ID}"
        client_secret: "${SAP_CLIENT_SECRET}"
        token_url: "https://192.168.1.103/sap/bc/sec/oauth2/token"
    
    settings:
      polling_interval: 60000  # ms
      batch_size: 50
      timeout: 60
    
    mappings:
      material: "API_PRODUCT_SRV/A_Product"
      purchase_order: "API_PURCHASEORDER_PROCESS_SRV/A_PurchaseOrder"
      sales_order: "API_SALES_ORDER_SRV/A_SalesOrder"
      production_order: "API_PRODUCTION_ORDER_2_SRV/A_ProductionOrder_2"
    
    health_check:
      enabled: true
      interval: 300  # seconds
      endpoint: "/sap/public/ping"
```

---

## åˆå§‹è¨­å®šæµç¨‹

### 1. äº’å‹•å¼ CLI è¨­å®š

```bash
$ ndh-admin init

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         æ­¡è¿ä½¿ç”¨ NDH åˆå§‹åŒ–è¨­å®šç²¾éˆ                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ­¥é©Ÿ 1/5: é¸æ“‡éƒ¨ç½²æ¨¡å¼

è«‹é¸æ“‡éƒ¨ç½²æ¨¡å¼:
  1) å–®æ©Ÿæ¨¡å¼ (Single Node)
  2) å¢é›†æ¨¡å¼ (Cluster)
  3) é›²ç«¯æ¨¡å¼ (Cloud)

æ‚¨çš„é¸æ“‡ [1]: 2

æ­¥é©Ÿ 2/5: ç¶²è·¯æƒæ

æ˜¯å¦è¦è‡ªå‹•æƒæç¶²è·¯ä»¥ç™¼ç¾ç³»çµ±? [Y/n]: Y

è«‹è¼¸å…¥è¦æƒæçš„ IP ç¯„åœ (å¤šå€‹ç¯„åœç”¨é€—è™Ÿåˆ†éš”):
[192.168.1.0/24]: 192.168.1.0/24,10.0.0.0/16

ğŸ” æ­£åœ¨æƒæç¶²è·¯...
  æƒæ 192.168.1.0/24... [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (254/254)
  æƒæ 10.0.0.0/16...    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (65536/65536)

âœ… æƒæå®Œæˆï¼ç™¼ç¾ 4 å€‹ç³»çµ±:

  1. InfluxDB 2.x
     åœ°å€: 192.168.1.100:8086
     ç‹€æ…‹: âœ… å¯é€£æ¥

  2. Omniverse Nucleus 2023.2.0
     åœ°å€: 192.168.1.101:3009
     ç‹€æ…‹: âœ… å¯é€£æ¥

  3. SAP ME 15.4
     åœ°å€: 192.168.1.102:8080
     ç‹€æ…‹: âš ï¸  éœ€è¦èªè­‰

  4. SAP S/4HANA 2022
     åœ°å€: 192.168.1.103:443
     ç‹€æ…‹: âš ï¸  éœ€è¦èªè­‰

æ­¥é©Ÿ 3/5: é…ç½®é€£æ¥å™¨

æ­£åœ¨è‡ªå‹•é…ç½®é€£æ¥å™¨...

[1/4] InfluxDB é€£æ¥å™¨
  âœ… è‡ªå‹•é…ç½®å®Œæˆ
  âœ… é€£æ¥æ¸¬è©¦é€šé
  âœ… ç™¼ç¾ 3 å€‹è³‡æ–™åº«: factory_data, quality_data, energy_data

[2/4] Omniverse é€£æ¥å™¨
  âœ… è‡ªå‹•é…ç½®å®Œæˆ
  âœ… é€£æ¥æ¸¬è©¦é€šé
  âœ… ç™¼ç¾ 2 å€‹å€‰åº«: Projects, Assets

[3/4] SAP ME é€£æ¥å™¨
  âš ï¸  éœ€è¦èªè­‰è³‡è¨Š
  
  è«‹è¼¸å…¥ SAP ME ä½¿ç”¨è€…åç¨±: admin
  è«‹è¼¸å…¥ SAP ME å¯†ç¢¼: ********
  
  âœ… èªè­‰æˆåŠŸ
  âœ… é€£æ¥æ¸¬è©¦é€šé
  âœ… ç™¼ç¾ 15 å€‹å¯¦é«”é›†

[4/4] SAP S/4HANA é€£æ¥å™¨
  âš ï¸  éœ€è¦ OAuth2 èªè­‰è³‡è¨Š
  
  è«‹è¼¸å…¥ Client ID: ndh-client
  è«‹è¼¸å…¥ Client Secret: ********
  
  âœ… èªè­‰æˆåŠŸ
  âœ… é€£æ¥æ¸¬è©¦é€šé
  âœ… API å¯ç”¨

æ­¥é©Ÿ 4/5: é…ç½®å„²å­˜

è«‹é¸æ“‡é…ç½®å„²å­˜ä½ç½®:
  1) æœ¬åœ°æª”æ¡ˆ (/etc/ndh/config.yaml)
  2) etcd
  3) Kubernetes ConfigMap

æ‚¨çš„é¸æ“‡ [1]: 1

âœ… é…ç½®å·²å„²å­˜åˆ° /etc/ndh/config.yaml

æ­¥é©Ÿ 5/5: å•Ÿå‹• NDH

æ˜¯å¦ç«‹å³å•Ÿå‹• NDH? [Y/n]: Y

ğŸš€ æ­£åœ¨å•Ÿå‹• NDH...
  âœ… Master ç¯€é»å•Ÿå‹•æˆåŠŸ
  âœ… Worker ç¯€é»å•Ÿå‹•æˆåŠŸ
  âœ… æ‰€æœ‰é€£æ¥å™¨å·²å•Ÿå‹•
  âœ… å¥åº·æª¢æŸ¥é€šé

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    NDH åˆå§‹åŒ–å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NDH å·²æˆåŠŸå•Ÿå‹•ä¸¦é€£æ¥åˆ°ä»¥ä¸‹ç³»çµ±:
  â€¢ InfluxDB (192.168.1.100:8086)
  â€¢ Omniverse (192.168.1.101:3009)
  â€¢ SAP ME (192.168.1.102:8080)
  â€¢ SAP S/4HANA (192.168.1.103:443)

Web UI: http://localhost:8080
API: http://localhost:8080/api/v1

ä¸‹ä¸€æ­¥:
  1. è¨ªå• Web UI æŸ¥çœ‹ç³»çµ±ç‹€æ…‹
  2. åŒ¯å…¥ IADL/FDL å®šç¾©
  3. é–‹å§‹ç›£æ§å’Œç®¡ç†æ‚¨çš„å·¥å» 

éœ€è¦å¹«åŠ©? åŸ·è¡Œ: ndh-admin help
```

---

### 2. éäº’å‹•å¼ CLI è¨­å®š

```bash
# ä½¿ç”¨é…ç½®æª”æ¡ˆ
$ ndh-admin init --config /path/to/config.yaml

# ä½¿ç”¨å‘½ä»¤åˆ—åƒæ•¸
$ ndh-admin init \
  --mode cluster \
  --scan-range "192.168.1.0/24" \
  --influxdb "192.168.1.100:8086" \
  --omniverse "192.168.1.101:3009" \
  --mes "192.168.1.102:8080" \
  --mes-type "sap-me" \
  --mes-user "admin" \
  --mes-password "password" \
  --erp "192.168.1.103:443" \
  --erp-type "sap-s4hana" \
  --erp-client-id "ndh-client" \
  --erp-client-secret "secret" \
  --auto-start
```

---

## Web UI è¨­å®šä»‹é¢

### 1. è¨­å®šç²¾éˆ (Setup Wizard)

**é é¢ 1: æ­¡è¿**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¡è¿ä½¿ç”¨ NDH                                           â”‚
â”‚                                                         â”‚
â”‚  é€™å€‹è¨­å®šç²¾éˆå°‡å”åŠ©æ‚¨:                                  â”‚
â”‚  â€¢ è‡ªå‹•ç™¼ç¾ç¶²è·¯ä¸Šçš„ç³»çµ±                                 â”‚
â”‚  â€¢ é…ç½®é€£æ¥å™¨                                           â”‚
â”‚  â€¢ æ¸¬è©¦é€£æ¥                                             â”‚
â”‚  â€¢ å•Ÿå‹• NDH                                             â”‚
â”‚                                                         â”‚
â”‚  é è¨ˆæ™‚é–“: 5-10 åˆ†é˜                                    â”‚
â”‚                                                         â”‚
â”‚                                   [é–‹å§‹è¨­å®š] [ç¨å¾Œè¨­å®š] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é é¢ 2: ç¶²è·¯æƒæ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥é©Ÿ 1/4: ç¶²è·¯æƒæ                                     â”‚
â”‚                                                         â”‚
â”‚  IP ç¯„åœ:  [192.168.1.0/24        ] [+ æ–°å¢ç¯„åœ]       â”‚
â”‚                                                         â”‚
â”‚  æƒæç«¯å£:                                              â”‚
â”‚  â˜‘ æ™‚åºè³‡æ–™åº« (InfluxDB, TimescaleDB)                  â”‚
â”‚  â˜‘ Omniverse Nucleus                                   â”‚
â”‚  â˜‘ MES ç³»çµ± (SAP ME, Opcenter)                         â”‚
â”‚  â˜‘ ERP ç³»çµ± (SAP S/4HANA, Oracle)                      â”‚
â”‚                                                         â”‚
â”‚  [é–‹å§‹æƒæ]                                             â”‚
â”‚                                                         â”‚
â”‚  æƒæé€²åº¦: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (254/254)       â”‚
â”‚                                                         â”‚
â”‚  ç™¼ç¾çš„ç³»çµ±:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ âœ… InfluxDB 2.x          192.168.1.100:8086      â”‚ â”‚
â”‚  â”‚ âœ… Omniverse Nucleus     192.168.1.101:3009      â”‚ â”‚
â”‚  â”‚ âš ï¸  SAP ME 15.4          192.168.1.102:8080      â”‚ â”‚
â”‚  â”‚ âš ï¸  SAP S/4HANA 2022     192.168.1.103:443       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â”‚                                       [ä¸Šä¸€æ­¥] [ä¸‹ä¸€æ­¥] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é é¢ 3: é…ç½®é€£æ¥å™¨**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥é©Ÿ 2/4: é…ç½®é€£æ¥å™¨                                   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€ InfluxDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ åœ°å€: 192.168.1.100:8086                          â”‚ â”‚
â”‚  â”‚ ç‰ˆæœ¬: 2.x                                         â”‚ â”‚
â”‚  â”‚ çµ„ç¹”: [idtf            ]                          â”‚ â”‚
â”‚  â”‚ Bucket: [factory_data    ]                        â”‚ â”‚
â”‚  â”‚ Token: [â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢]                         â”‚ â”‚
â”‚  â”‚                                                   â”‚ â”‚
â”‚  â”‚ [æ¸¬è©¦é€£æ¥] âœ… é€£æ¥æˆåŠŸ                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€ Omniverse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ åœ°å€: 192.168.1.101:3009                          â”‚ â”‚
â”‚  â”‚ ç‰ˆæœ¬: 2023.2.0                                    â”‚ â”‚
â”‚  â”‚ å€‰åº«: [Projects        ]                          â”‚ â”‚
â”‚  â”‚ USD è·¯å¾‘: [omniverse://192.168.1.101/Projects/... â”‚ â”‚
â”‚  â”‚ ä½¿ç”¨è€…: [admin          ]                         â”‚ â”‚
â”‚  â”‚ å¯†ç¢¼: [â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢]                         â”‚ â”‚
â”‚  â”‚                                                   â”‚ â”‚
â”‚  â”‚ [æ¸¬è©¦é€£æ¥] âœ… é€£æ¥æˆåŠŸ                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€ SAP ME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ åœ°å€: 192.168.1.102:8080                          â”‚ â”‚
â”‚  â”‚ ç‰ˆæœ¬: 15.4                                        â”‚ â”‚
â”‚  â”‚ ä½¿ç”¨è€…: [admin          ]                         â”‚ â”‚
â”‚  â”‚ å¯†ç¢¼: [â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢]                         â”‚ â”‚
â”‚  â”‚                                                   â”‚ â”‚
â”‚  â”‚ [æ¸¬è©¦é€£æ¥] âœ… é€£æ¥æˆåŠŸ                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â”‚                                       [ä¸Šä¸€æ­¥] [ä¸‹ä¸€æ­¥] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é é¢ 4: æ¸¬è©¦èˆ‡é©—è­‰**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥é©Ÿ 3/4: æ¸¬è©¦èˆ‡é©—è­‰                                   â”‚
â”‚                                                         â”‚
â”‚  æ­£åœ¨æ¸¬è©¦æ‰€æœ‰é€£æ¥å™¨...                                  â”‚
â”‚                                                         â”‚
â”‚  âœ… InfluxDB é€£æ¥å™¨                                     â”‚
â”‚     â€¢ é€£æ¥æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚     â€¢ å¯«å…¥æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚     â€¢ æŸ¥è©¢æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚                                                         â”‚
â”‚  âœ… Omniverse é€£æ¥å™¨                                    â”‚
â”‚     â€¢ é€£æ¥æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚     â€¢ USD è¨ªå•: âœ… é€šé                                 â”‚
â”‚     â€¢ å¯«å…¥æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚                                                         â”‚
â”‚  âœ… SAP ME é€£æ¥å™¨                                       â”‚
â”‚     â€¢ é€£æ¥æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚     â€¢ API è¨ªå•: âœ… é€šé                                 â”‚
â”‚     â€¢ æ•¸æ“šæŸ¥è©¢: âœ… é€šé                                 â”‚
â”‚                                                         â”‚
â”‚  âœ… SAP S/4HANA é€£æ¥å™¨                                  â”‚
â”‚     â€¢ é€£æ¥æ¸¬è©¦: âœ… é€šé                                 â”‚
â”‚     â€¢ OAuth2 èªè­‰: âœ… é€šé                              â”‚
â”‚     â€¢ API è¨ªå•: âœ… é€šé                                 â”‚
â”‚                                                         â”‚
â”‚  æ‰€æœ‰æ¸¬è©¦é€šéï¼                                         â”‚
â”‚                                                         â”‚
â”‚                                       [ä¸Šä¸€æ­¥] [ä¸‹ä¸€æ­¥] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é é¢ 5: å®Œæˆ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥é©Ÿ 4/4: å®Œæˆ                                         â”‚
â”‚                                                         â”‚
â”‚  âœ… NDH åˆå§‹åŒ–å®Œæˆï¼                                    â”‚
â”‚                                                         â”‚
â”‚  å·²é…ç½®çš„é€£æ¥å™¨:                                        â”‚
â”‚  â€¢ InfluxDB (192.168.1.100:8086)                       â”‚
â”‚  â€¢ Omniverse (192.168.1.101:3009)                      â”‚
â”‚  â€¢ SAP ME (192.168.1.102:8080)                         â”‚
â”‚  â€¢ SAP S/4HANA (192.168.1.103:443)                     â”‚
â”‚                                                         â”‚
â”‚  é…ç½®å·²å„²å­˜åˆ°: /etc/ndh/config.yaml                     â”‚
â”‚                                                         â”‚
â”‚  ä¸‹ä¸€æ­¥:                                                â”‚
â”‚  1. åŒ¯å…¥ IADL/FDL å®šç¾©                                  â”‚
â”‚  2. é–‹å§‹ç›£æ§å’Œç®¡ç†æ‚¨çš„å·¥å»                               â”‚
â”‚                                                         â”‚
â”‚                          [å•Ÿå‹• NDH] [åŒ¯å‡ºé…ç½®] [å®Œæˆ]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. é€£æ¥å™¨ç®¡ç†ä»‹é¢

**é€£æ¥å™¨åˆ—è¡¨é é¢**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é€£æ¥å™¨ç®¡ç†                                      [+ æ–°å¢é€£æ¥å™¨] [é‡æ–°æƒæ] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€ InfluxDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ åç¨±: influxdb_production                     ç‹€æ…‹: âœ… é‹è¡Œä¸­     â”‚ â”‚
â”‚  â”‚ åœ°å€: 192.168.1.100:8086                                         â”‚ â”‚
â”‚  â”‚ ç‰ˆæœ¬: 2.x                                                        â”‚ â”‚
â”‚  â”‚ å¥åº·ç‹€æ…‹: âœ… å¥åº·                                                â”‚ â”‚
â”‚  â”‚ æœ€å¾Œæª¢æŸ¥: 2025-10-15 14:30:00                                   â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ [ç·¨è¼¯] [æ¸¬è©¦] [åœæ­¢] [åˆªé™¤]                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ Omniverse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ åç¨±: omniverse_production                    ç‹€æ…‹: âœ… é‹è¡Œä¸­     â”‚ â”‚
â”‚  â”‚ åœ°å€: 192.168.1.101:3009                                         â”‚ â”‚
â”‚  â”‚ ç‰ˆæœ¬: 2023.2.0                                                   â”‚ â”‚
â”‚  â”‚ å¥åº·ç‹€æ…‹: âœ… å¥åº·                                                â”‚ â”‚
â”‚  â”‚ æœ€å¾Œæª¢æŸ¥: 2025-10-15 14:30:00                                   â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ [ç·¨è¼¯] [æ¸¬è©¦] [åœæ­¢] [åˆªé™¤]                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ SAP ME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ åç¨±: sap_me_production                       ç‹€æ…‹: âš ï¸  è­¦å‘Š      â”‚ â”‚
â”‚  â”‚ åœ°å€: 192.168.1.102:8080                                         â”‚ â”‚
â”‚  â”‚ ç‰ˆæœ¬: 15.4                                                       â”‚ â”‚
â”‚  â”‚ å¥åº·ç‹€æ…‹: âš ï¸  éŸ¿æ‡‰æ…¢ (1200ms)                                    â”‚ â”‚
â”‚  â”‚ æœ€å¾Œæª¢æŸ¥: 2025-10-15 14:30:00                                   â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ [ç·¨è¼¯] [æ¸¬è©¦] [é‡å•Ÿ] [åˆªé™¤]                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CLI è¨­å®šå·¥å…·

### 1. ndh-admin å‘½ä»¤

```bash
# åˆå§‹åŒ– NDH
ndh-admin init [OPTIONS]

# é¸é …:
  --mode <mode>                éƒ¨ç½²æ¨¡å¼ (single|cluster|cloud)
  --config <file>              é…ç½®æª”æ¡ˆè·¯å¾‘
  --scan-range <range>         IP æƒæç¯„åœ
  --auto-discover              è‡ªå‹•ç™¼ç¾ç³»çµ±
  --auto-configure             è‡ªå‹•é…ç½®é€£æ¥å™¨
  --auto-start                 è‡ªå‹•å•Ÿå‹• NDH
  --interactive                äº’å‹•å¼è¨­å®š
  --non-interactive            éäº’å‹•å¼è¨­å®š
  
  # é€£æ¥å™¨é…ç½®
  --influxdb <host:port>       InfluxDB åœ°å€
  --influxdb-token <token>     InfluxDB Token
  --omniverse <host:port>      Omniverse Nucleus åœ°å€
  --mes <host:port>            MES ç³»çµ±åœ°å€
  --mes-type <type>            MES é¡å‹ (sap-me|opcenter)
  --erp <host:port>            ERP ç³»çµ±åœ°å€
  --erp-type <type>            ERP é¡å‹ (sap-s4hana|oracle)

# ç¯„ä¾‹:
$ ndh-admin init --auto-discover --auto-configure --auto-start

$ ndh-admin init \
  --config /etc/ndh/config.yaml \
  --non-interactive

$ ndh-admin init \
  --mode cluster \
  --influxdb "192.168.1.100:8086" \
  --influxdb-token "my-token" \
  --omniverse "192.168.1.101:3009" \
  --auto-start
```

### 2. é€£æ¥å™¨ç®¡ç†å‘½ä»¤

```bash
# åˆ—å‡ºæ‰€æœ‰é€£æ¥å™¨
$ ndh-admin connector list

NAME                    TYPE        STATUS    HEALTH
influxdb_production     influxdb    running   âœ… healthy
omniverse_production    omniverse   running   âœ… healthy
sap_me_production       mes         running   âš ï¸  slow
sap_s4hana_production   erp         running   âœ… healthy

# æ¸¬è©¦é€£æ¥å™¨
$ ndh-admin connector test influxdb_production

Testing influxdb_production...
  âœ… Connection test: PASSED
  âœ… Write test: PASSED
  âœ… Query test: PASSED

All tests passed!

# å•Ÿå‹•/åœæ­¢é€£æ¥å™¨
$ ndh-admin connector start influxdb_production
$ ndh-admin connector stop influxdb_production
$ ndh-admin connector restart influxdb_production

# æŸ¥çœ‹é€£æ¥å™¨è©³æƒ…
$ ndh-admin connector show influxdb_production

Name: influxdb_production
Type: influxdb
Status: running
Health: âœ… healthy

Connection:
  Host: 192.168.1.100
  Port: 8086
  Protocol: http
  Org: idtf
  Bucket: factory_data

Settings:
  Timeout: 10s
  Max Retries: 3
  Batch Size: 5000

Health Check:
  Enabled: true
  Interval: 30s
  Last Check: 2025-10-15 14:30:00
  Status: âœ… healthy

# æ–°å¢é€£æ¥å™¨
$ ndh-admin connector add \
  --name my_influxdb \
  --type influxdb \
  --host 192.168.1.100 \
  --port 8086 \
  --org idtf \
  --bucket factory_data \
  --token my-token

# åˆªé™¤é€£æ¥å™¨
$ ndh-admin connector delete influxdb_production

# åŒ¯å‡ºé€£æ¥å™¨é…ç½®
$ ndh-admin connector export influxdb_production > influxdb.yaml

# åŒ¯å…¥é€£æ¥å™¨é…ç½®
$ ndh-admin connector import influxdb.yaml
```

### 3. ç¶²è·¯æƒæå‘½ä»¤

```bash
# æƒæç¶²è·¯
$ ndh-admin scan --range "192.168.1.0/24"

Scanning 192.168.1.0/24...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (254/254)

Discovered systems:
  âœ… InfluxDB 2.x          192.168.1.100:8086
  âœ… Omniverse Nucleus     192.168.1.101:3009
  âš ï¸  SAP ME 15.4          192.168.1.102:8080
  âš ï¸  SAP S/4HANA 2022     192.168.1.103:443

# æƒæç‰¹å®šé¡å‹çš„ç³»çµ±
$ ndh-admin scan --range "192.168.1.0/24" --type influxdb

# æƒæä¸¦è‡ªå‹•é…ç½®
$ ndh-admin scan --range "192.168.1.0/24" --auto-configure

# åŒ¯å‡ºæƒæçµæœ
$ ndh-admin scan --range "192.168.1.0/24" --output scan_results.json
```

---

## é…ç½®æª”æ¡ˆæ ¼å¼

### å®Œæ•´é…ç½®ç¯„ä¾‹

```yaml
# /etc/ndh/config.yaml

# NDH å…¨åŸŸé…ç½®
ndh:
  mode: "cluster"  # single, cluster, cloud
  version: "3.5.1"
  
  # å¢é›†é…ç½®
  cluster:
    master_nodes:
      - "192.168.1.10:6443"
      - "192.168.1.11:6443"
      - "192.168.1.12:6443"
    
    worker_nodes:
      - "192.168.1.20:6443"
      - "192.168.1.21:6443"
      - "192.168.1.22:6443"
  
  # ç¶²è·¯é…ç½®
  network:
    listen_address: "0.0.0.0"
    api_port: 8080
    grpc_port: 9090

# é€£æ¥å™¨é…ç½®
connectors:
  # æ™‚åºè³‡æ–™åº«
  - name: "influxdb_production"
    type: "influxdb"
    enabled: true
    version: "2.x"
    connection:
      host: "192.168.1.100"
      port: 8086
      protocol: "http"
      org: "idtf"
      bucket: "factory_data"
      token: "${INFLUXDB_TOKEN}"
    settings:
      timeout: 10
      max_retries: 3
      batch_size: 5000
      flush_interval: 1000
    health_check:
      enabled: true
      interval: 30
      endpoint: "/health"
  
  # Omniverse
  - name: "omniverse_production"
    type: "omniverse"
    enabled: true
    nucleus_version: "2023.2.0"
    connection:
      host: "192.168.1.101"
      port: 3009
      repo: "Projects"
      usd_stage_path: "omniverse://192.168.1.101/Projects/Factory/factory.usd"
      auth:
        username: "${OMNIVERSE_USER}"
        password: "${OMNIVERSE_PASSWORD}"
    settings:
      sync_interval: 1000
      batch_updates: true
      enable_live_sync: true
      max_prims_per_batch: 1000
    health_check:
      enabled: true
      interval: 60
  
  # MES
  - name: "sap_me_production"
    type: "mes"
    enabled: true
    vendor: "sap"
    product: "SAP ME"
    version: "15.4"
    connection:
      host: "192.168.1.102"
      port: 8080
      protocol: "http"
      base_url: "http://192.168.1.102:8080/odata/v4"
      auth:
        type: "basic"
        username: "${SAP_ME_USER}"
        password: "${SAP_ME_PASSWORD}"
    settings:
      polling_interval: 5000
      batch_size: 100
      timeout: 30
    mappings:
      work_order: "WorkOrders"
      operation: "Operations"
      material: "Materials"
      production_data: "ProductionData"
    health_check:
      enabled: true
      interval: 30
      endpoint: "/sap/public/ping"
  
  # ERP
  - name: "sap_s4hana_production"
    type: "erp"
    enabled: true
    vendor: "sap"
    product: "S/4HANA"
    version: "2022"
    connection:
      host: "192.168.1.103"
      port: 443
      protocol: "https"
      base_url: "https://192.168.1.103/sap/opu/odata/sap"
      auth:
        type: "oauth2"
        client_id: "${SAP_CLIENT_ID}"
        client_secret: "${SAP_CLIENT_SECRET}"
        token_url: "https://192.168.1.103/sap/bc/sec/oauth2/token"
    settings:
      polling_interval: 60000
      batch_size: 50
      timeout: 60
    mappings:
      material: "API_PRODUCT_SRV/A_Product"
      purchase_order: "API_PURCHASEORDER_PROCESS_SRV/A_PurchaseOrder"
      sales_order: "API_SALES_ORDER_SRV/A_SalesOrder"
      production_order: "API_PRODUCTION_ORDER_2_SRV/A_ProductionOrder_2"
    health_check:
      enabled: true
      interval: 300
      endpoint: "/sap/public/ping"

# æ—¥èªŒé…ç½®
logging:
  level: "info"  # debug, info, warning, error
  output: "stdout"  # stdout, file, syslog
  file: "/var/log/ndh/ndh.log"
  max_size: "100MB"
  max_backups: 10

# ç›£æ§é…ç½®
monitoring:
  enabled: true
  prometheus:
    enabled: true
    port: 9091
  grafana:
    enabled: true
    port: 3000
```

---

## é€£æ¥å™¨æ¸¬è©¦èˆ‡é©—è­‰

### 1. è‡ªå‹•åŒ–æ¸¬è©¦å¥—ä»¶

```python
class ConnectorTestSuite:
    def __init__(self, connector_config: dict):
        self.config = connector_config
        self.connector = self.create_connector()
    
    def run_all_tests(self) -> dict:
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        results = {
            'connector_name': self.config['name'],
            'connector_type': self.config['type'],
            'tests': []
        }
        
        # 1. é€£æ¥æ¸¬è©¦
        results['tests'].append(self.test_connection())
        
        # 2. èªè­‰æ¸¬è©¦
        results['tests'].append(self.test_authentication())
        
        # 3. è®€å–æ¸¬è©¦
        results['tests'].append(self.test_read())
        
        # 4. å¯«å…¥æ¸¬è©¦
        results['tests'].append(self.test_write())
        
        # 5. æ•ˆèƒ½æ¸¬è©¦
        results['tests'].append(self.test_performance())
        
        # 6. æ•…éšœæ¢å¾©æ¸¬è©¦
        results['tests'].append(self.test_failover())
        
        return results
    
    def test_connection(self) -> dict:
        """æ¸¬è©¦é€£æ¥"""
        try:
            start_time = time.time()
            self.connector.connect()
            latency = (time.time() - start_time) * 1000
            
            return {
                'name': 'Connection Test',
                'status': 'passed',
                'latency_ms': latency,
                'message': f'Connected successfully in {latency:.2f}ms'
            }
        except Exception as e:
            return {
                'name': 'Connection Test',
                'status': 'failed',
                'error': str(e)
            }
    
    def test_authentication(self) -> dict:
        """æ¸¬è©¦èªè­‰"""
        try:
            self.connector.authenticate()
            return {
                'name': 'Authentication Test',
                'status': 'passed',
                'message': 'Authentication successful'
            }
        except Exception as e:
            return {
                'name': 'Authentication Test',
                'status': 'failed',
                'error': str(e)
            }
    
    def test_read(self) -> dict:
        """æ¸¬è©¦è®€å–"""
        try:
            data = self.connector.read_test_data()
            return {
                'name': 'Read Test',
                'status': 'passed',
                'records_read': len(data),
                'message': f'Successfully read {len(data)} records'
            }
        except Exception as e:
            return {
                'name': 'Read Test',
                'status': 'failed',
                'error': str(e)
            }
    
    def test_write(self) -> dict:
        """æ¸¬è©¦å¯«å…¥"""
        try:
            test_data = self.generate_test_data()
            self.connector.write(test_data)
            return {
                'name': 'Write Test',
                'status': 'passed',
                'records_written': len(test_data),
                'message': f'Successfully wrote {len(test_data)} records'
            }
        except Exception as e:
            return {
                'name': 'Write Test',
                'status': 'failed',
                'error': str(e)
            }
    
    def test_performance(self) -> dict:
        """æ¸¬è©¦æ•ˆèƒ½"""
        try:
            # å¯«å…¥æ•ˆèƒ½
            write_start = time.time()
            test_data = self.generate_test_data(count=1000)
            self.connector.write(test_data)
            write_time = time.time() - write_start
            write_throughput = len(test_data) / write_time
            
            # è®€å–æ•ˆèƒ½
            read_start = time.time()
            data = self.connector.read_test_data(limit=1000)
            read_time = time.time() - read_start
            read_throughput = len(data) / read_time
            
            return {
                'name': 'Performance Test',
                'status': 'passed',
                'write_throughput': f'{write_throughput:.2f} records/s',
                'read_throughput': f'{read_throughput:.2f} records/s',
                'message': 'Performance test completed'
            }
        except Exception as e:
            return {
                'name': 'Performance Test',
                'status': 'failed',
                'error': str(e)
            }
```

### 2. å¥åº·æª¢æŸ¥

```python
class ConnectorHealthCheck:
    def __init__(self, connector_config: dict):
        self.config = connector_config
        self.connector = self.create_connector()
    
    def check_health(self) -> dict:
        """æª¢æŸ¥é€£æ¥å™¨å¥åº·ç‹€æ…‹"""
        health = {
            'connector_name': self.config['name'],
            'connector_type': self.config['type'],
            'timestamp': datetime.now().isoformat(),
            'status': 'unknown',
            'checks': []
        }
        
        # 1. é€£æ¥æª¢æŸ¥
        connection_check = self.check_connection()
        health['checks'].append(connection_check)
        
        # 2. éŸ¿æ‡‰æ™‚é–“æª¢æŸ¥
        latency_check = self.check_latency()
        health['checks'].append(latency_check)
        
        # 3. éŒ¯èª¤ç‡æª¢æŸ¥
        error_rate_check = self.check_error_rate()
        health['checks'].append(error_rate_check)
        
        # 4. è³‡æºä½¿ç”¨æª¢æŸ¥
        resource_check = self.check_resources()
        health['checks'].append(resource_check)
        
        # ç¢ºå®šæ•´é«”ç‹€æ…‹
        if all(check['status'] == 'healthy' for check in health['checks']):
            health['status'] = 'healthy'
        elif any(check['status'] == 'critical' for check in health['checks']):
            health['status'] = 'critical'
        else:
            health['status'] = 'degraded'
        
        return health
    
    def check_connection(self) -> dict:
        """æª¢æŸ¥é€£æ¥"""
        try:
            self.connector.ping()
            return {
                'name': 'Connection',
                'status': 'healthy',
                'message': 'Connection is active'
            }
        except Exception as e:
            return {
                'name': 'Connection',
                'status': 'critical',
                'message': f'Connection failed: {str(e)}'
            }
    
    def check_latency(self) -> dict:
        """æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“"""
        try:
            start_time = time.time()
            self.connector.ping()
            latency = (time.time() - start_time) * 1000
            
            if latency < 100:
                status = 'healthy'
            elif latency < 500:
                status = 'degraded'
            else:
                status = 'critical'
            
            return {
                'name': 'Latency',
                'status': status,
                'value': f'{latency:.2f}ms',
                'threshold': '< 100ms (healthy), < 500ms (degraded)'
            }
        except Exception as e:
            return {
                'name': 'Latency',
                'status': 'critical',
                'message': f'Latency check failed: {str(e)}'
            }
    
    def check_error_rate(self) -> dict:
        """æª¢æŸ¥éŒ¯èª¤ç‡"""
        try:
            metrics = self.connector.get_metrics()
            error_rate = metrics['error_count'] / metrics['total_requests'] * 100
            
            if error_rate < 1:
                status = 'healthy'
            elif error_rate < 5:
                status = 'degraded'
            else:
                status = 'critical'
            
            return {
                'name': 'Error Rate',
                'status': status,
                'value': f'{error_rate:.2f}%',
                'threshold': '< 1% (healthy), < 5% (degraded)'
            }
        except Exception as e:
            return {
                'name': 'Error Rate',
                'status': 'unknown',
                'message': f'Error rate check failed: {str(e)}'
            }
```

---

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### 1. ç„¡æ³•ç™¼ç¾ç³»çµ±

**å•é¡Œ**: ç¶²è·¯æƒæç„¡æ³•ç™¼ç¾ä»»ä½•ç³»çµ±

**å¯èƒ½åŸå› **:
- ç¶²è·¯ä¸é€š
- é˜²ç«ç‰†é˜»æ“‹
- IP ç¯„åœéŒ¯èª¤
- ç«¯å£æœªé–‹æ”¾

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. æª¢æŸ¥ç¶²è·¯é€£é€šæ€§
$ ping 192.168.1.100

# 2. æª¢æŸ¥ç«¯å£æ˜¯å¦é–‹æ”¾
$ nc -zv 192.168.1.100 8086

# 3. æª¢æŸ¥é˜²ç«ç‰†è¦å‰‡
$ sudo iptables -L

# 4. ä½¿ç”¨ nmap æƒæ
$ nmap -p 8086 192.168.1.100

# 5. æ‰‹å‹•æŒ‡å®šç³»çµ±
$ ndh-admin connector add \
  --name my_influxdb \
  --type influxdb \
  --host 192.168.1.100 \
  --port 8086
```

#### 2. é€£æ¥æ¸¬è©¦å¤±æ•—

**å•é¡Œ**: é€£æ¥å™¨é…ç½®å¾Œæ¸¬è©¦å¤±æ•—

**å¯èƒ½åŸå› **:
- èªè­‰è³‡è¨ŠéŒ¯èª¤
- ç¶²è·¯å•é¡Œ
- ç³»çµ±é…ç½®éŒ¯èª¤
- ç‰ˆæœ¬ä¸ç›¸å®¹

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. æª¢æŸ¥é€£æ¥å™¨æ—¥èªŒ
$ ndh-admin connector logs influxdb_production

# 2. æ¸¬è©¦é€£æ¥
$ ndh-admin connector test influxdb_production --verbose

# 3. æª¢æŸ¥èªè­‰è³‡è¨Š
$ ndh-admin connector show influxdb_production

# 4. é‡æ–°é…ç½®
$ ndh-admin connector edit influxdb_production
```

#### 3. æ•ˆèƒ½å•é¡Œ

**å•é¡Œ**: é€£æ¥å™¨éŸ¿æ‡‰æ…¢æˆ–è¶…æ™‚

**å¯èƒ½åŸå› **:
- ç¶²è·¯å»¶é²
- ç³»çµ±è² è¼‰é«˜
- æ‰¹æ¬¡å¤§å°ä¸ç•¶
- é€£æ¥æ± é…ç½®ä¸ç•¶

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. æª¢æŸ¥å»¶é²
$ ndh-admin connector ping influxdb_production

# 2. èª¿æ•´æ‰¹æ¬¡å¤§å°
$ ndh-admin connector config influxdb_production \
  --set batch_size=1000

# 3. èª¿æ•´è¶…æ™‚æ™‚é–“
$ ndh-admin connector config influxdb_production \
  --set timeout=30

# 4. èª¿æ•´é€£æ¥æ± 
$ ndh-admin connector config influxdb_production \
  --set connection_pool.max_size=50
```

---

## æœ€ä½³å¯¦è¸

### 1. å®‰å…¨æ€§

- âœ… ä½¿ç”¨ç’°å¢ƒè®Šæ•¸å„²å­˜æ•æ„Ÿè³‡è¨Šï¼ˆTokenã€å¯†ç¢¼ï¼‰
- âœ… å•Ÿç”¨ TLS/SSL åŠ å¯†
- âœ… å®šæœŸè¼ªæ›èªè­‰è³‡è¨Š
- âœ… é™åˆ¶ç¶²è·¯è¨ªå•ï¼ˆé˜²ç«ç‰†è¦å‰‡ï¼‰
- âœ… å•Ÿç”¨å¯©è¨ˆæ—¥èªŒ

### 2. å¯é æ€§

- âœ… å•Ÿç”¨å¥åº·æª¢æŸ¥
- âœ… é…ç½®é‡è©¦æ©Ÿåˆ¶
- âœ… è¨­ç½®åˆç†çš„è¶…æ™‚æ™‚é–“
- âœ… ç›£æ§é€£æ¥å™¨ç‹€æ…‹
- âœ… å®šæœŸå‚™ä»½é…ç½®

### 3. æ•ˆèƒ½

- âœ… èª¿æ•´æ‰¹æ¬¡å¤§å°
- âœ… ä½¿ç”¨é€£æ¥æ± 
- âœ… å•Ÿç”¨å¿«å–
- âœ… å„ªåŒ–è¼ªè©¢é–“éš”
- âœ… ç›£æ§æ•ˆèƒ½æŒ‡æ¨™

### 4. å¯ç¶­è­·æ€§

- âœ… ä½¿ç”¨é…ç½®å³ä»£ç¢¼
- âœ… ç‰ˆæœ¬æ§åˆ¶é…ç½®æª”æ¡ˆ
- âœ… æ–‡æª”åŒ–è‡ªè¨‚é…ç½®
- âœ… å®šæœŸå¯©æŸ¥å’Œæ›´æ–°
- âœ… è‡ªå‹•åŒ–æ¸¬è©¦

---

## ç¸½çµ

NDH è‡ªå‹•åŒ–åˆå§‹è¨­å®šèˆ‡é€£æ¥å™¨é…ç½®ç³»çµ±æä¾›äº†ï¼š

1. âœ… **é›¶é…ç½®å„ªå…ˆ**: è‡ªå‹•ç™¼ç¾å’Œé…ç½®
2. âœ… **å¤šç¨®é…ç½®æ–¹å¼**: CLIã€Web UIã€é…ç½®æª”æ¡ˆ
3. âœ… **å®Œæ•´çš„æ¸¬è©¦èˆ‡é©—è­‰**: è‡ªå‹•åŒ–æ¸¬è©¦å¥—ä»¶
4. âœ… **å¥åº·ç›£æ§**: æŒçºŒç›£æ§é€£æ¥å™¨ç‹€æ…‹
5. âœ… **æ•…éšœæ’é™¤**: è©³ç´°çš„è¨ºæ–·å’Œè§£æ±ºæ–¹æ¡ˆ

é€™å°‡å¤§å¹…é™ä½ NDH çš„éƒ¨ç½²é–€æª»ï¼Œå¾æ•¸å¤©ç¸®çŸ­åˆ°æ•¸å°æ™‚ï¼Œä¸¦æ¸›å°‘é…ç½®éŒ¯èª¤ï¼Œæå‡ä½¿ç”¨è€…é«”é©—ã€‚

---

**Â© 2025 IDTF Consortium. All rights reserved.**

